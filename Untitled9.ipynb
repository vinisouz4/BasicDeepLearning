{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyML9GjZb15Y541Vv6dKKxcP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinisouz4/BasicDeepLearning/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rede Neural Python\n",
        "\n",
        "\n",
        "## Importação das tabelas"
      ],
      "metadata": {
        "id": "hUjNEEKYfNhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YAPHj_5berBA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a conversão de imagem para tensor\n",
        "transfrom = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "aNTbMILwfL6R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Faz o download e carrega a parte de treino do dataset\n",
        "trainset = datasets.MNIST(\n",
        "    \"./MNIST_data/\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transfrom\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwB4SuYsgSWF",
        "outputId": "87f39e06-7b46-48d3-c375-f568089b9349"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 644kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.56MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.59MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9QKQq4ngq3X",
        "outputId": "562b6fd6-7de4-4ba5-f0e7-63aa9beaea4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./MNIST_data/\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um buffer para os dados por parte\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "zmyrQQkGgtVd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-bbVgTehEFm",
        "outputId": "7cf3565f-3a9e-43bc-80ee-963f0aadc1eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7c6cbafe6990>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega a parte de validação do dataset\n",
        "valset = datasets.MNIST(\n",
        "    \"./MNIST_data/\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transfrom\n",
        ")"
      ],
      "metadata": {
        "id": "6a-HzFA1hFH1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj4Pa9W9he3W",
        "outputId": "e6b8e592-4609-4a93-a450-d7e581c03a92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./MNIST_data/\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um buffer para pegar os dados validados por partes\n",
        "valloader = torch.utils.data.DataLoader(\n",
        "    valset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "Mtnn69Vahlns"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3PYCTh_hv11",
        "outputId": "9d4a80cb-7e44-47ba-f7d8-b28c0ea2dcd7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7c6cbb79e990>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar a imagem em um gráfico para verificar com ela é retornada\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Explicação da sintaxe abaixo:\n",
        "\n",
        "images[0]:\n",
        "  images é um lote (batch) de imagens retornado pelo DataLoader. Ele é um tensor do PyTorch.\n",
        "  images[0] acessa a primeira imagem dentro desse lote. Portanto, images[0] também é um tensor do PyTorch, representando uma única imagem.\n",
        "\n",
        ".numpy():\n",
        "  .numpy() é um método dos tensores do PyTorch que os converte para arrays NumPy. O Matplotlib (usado por plt.imshow) trabalha com arrays NumPy, não com tensores do PyTorch. Portanto, essa conversão é necessária para que o Matplotlib possa exibir a imagem.\n",
        "\n",
        ".squeeze():\n",
        "  -> .squeeze() remove dimensões unitárias (dimensões com tamanho 1) de um array. No contexto de imagens, isso é importante porque as imagens geralmente têm uma dimensão extra para o canal de cor, mesmo quando são em escala de cinza.\n",
        "  -> Por exemplo, uma imagem em escala de cinza 28x28 pode ter o formato (1, 28, 28), onde o '1' representa um único canal (escala de cinza). O squeeze() transformaria esse formato em (28, 28), que é o formato esperado pelo plt.imshow para imagens em escala de cinza. Se a imagem fosse colorida (RGB), o formato poderia ser (3, 28, 28) e o squeeze() não faria nenhuma alteração nesse caso, pois não há dimensões unitárias.\n",
        "\n",
        "plt.imshow(..., cmap=\"gray_r\"):\n",
        "  -> plt.imshow() é uma função do Matplotlib que exibe uma imagem.\n",
        "  -> O primeiro argumento é o array NumPy que representa a imagem.\n",
        "     cmap=\"gray_r\" define o mapa de cores (colormap) como \"gray_r\". \"gray_r\" significa \"gray reversed\", ou seja, tons mais claros representam valores menores e tons mais escuros representam valores maiores. Se você usasse apenas cmap=\"gray\", seria o contrário.\n",
        "\"\"\"\n",
        "\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap=\"gray_r\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "O19bHWLNhw0s",
        "outputId": "bff77f82-f20c-4e0d-e867-2e7546420d79"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c6cb7c37a50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as dimensões do tensor de cada imagem\n",
        "print(images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI9r-NYNjF2F",
        "outputId": "cd13dd63-2922-4370-cf2b-eb049e53056e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Explicação da Classe e dos métodos presentes na mesma:\n",
        "\n",
        "1. class Modelo(nn.Module):\n",
        "-> Esta linha define uma nova classe chamada Modelo que herda de nn.Module. Em PyTorch, todas as redes neurais personalizadas devem herdar de nn.Module. Isso fornece funcionalidades essenciais para o treinamento e a inferência, como o rastreamento de parâmetros e o cálculo de gradientes.\n",
        "\n",
        "2. def __init__(self):\n",
        "-> Este é o construtor da classe. Ele é chamado quando você cria uma instância da classe Modelo. Aqui, você define as camadas da sua rede.\n",
        "\n",
        "3. super(Modelo, self).__init__()\n",
        "-> Esta linha é crucial. Ela chama o construtor da classe pai (nn.Module). É essencial para inicializar corretamente a classe base e garantir que a sua rede funcione corretamente.\n",
        "\n",
        "4. self.linear1 = nn.Linear(28*28, 128)\n",
        "-> Esta linha define a primeira camada linear (totalmente conectada) da sua rede.\n",
        "-> nn.Linear(input_features, output_features) cria uma camada linear.\n",
        "-> 28*28 é o número de neurônios na camada de entrada. Assumindo que você está trabalhando com imagens 28x28 (como no MNIST), você tem 784 pixels de entrada.\n",
        "-> 128 é o número de neurônios na camada de saída desta camada linear. Portanto, esta camada transforma um vetor de entrada de tamanho 784 em um vetor de tamanho 128.\n",
        "\n",
        "5. self.linear2 = nn.Linear(128, 64)\n",
        "-> Esta linha define a segunda camada linear.\n",
        "-> 128 é o número de neurônios na camada de entrada desta camada, correspondente à saída da self.linear1.\n",
        "-> 64 é o número de neurônios na camada de saída desta camada.\n",
        "\n",
        "6. self.linear3 = nn.Linear(64, 10)\n",
        "-> Esta linha define a terceira e última camada linear (camada de saída).\n",
        "-> 64 é o número de neurônios na camada de entrada.\n",
        "-> 10 é o número de neurônios na camada de saída. Assumindo um problema de classificação com 10 classes (como no MNIST, que tem dígitos de 0 a 9), você precisa de 10 neurônios na camada de saída, um para cada classe.\n",
        "\n",
        "7. def forward(self, x):\n",
        "->Este método define o fluxo dos dados através da rede. Ele recebe a entrada x e retorna a saída da rede.\n",
        "\n",
        "8. x = F.relu(self.linear1(x))\n",
        "-> Esta linha aplica a primeira camada linear (self.linear1) à entrada x e, em seguida, aplica a função de ativação ReLU (Rectified Linear Unit) ao resultado.\n",
        "-> self.linear1(x) executa a multiplicação da matriz de entrada x pelos pesos da camada self.linear1 e adiciona o bias.\n",
        "-> F.relu() aplica a função ReLU, que define os valores negativos como zero e mantém os valores positivos inalterados: f(x) = max(0, x).\n",
        "\n",
        "9. x = F.relu(self.linear2(x))\n",
        "-> Semelhante à linha anterior, esta linha aplica a segunda camada linear (self.linear2) seguida pela função de ativação ReLU.\n",
        "\n",
        "10. x = self.linear3(x)\n",
        "-> Aqui, a terceira camada linear (self.linear3) é aplicada. Não há uma função de ativação ReLU aqui. A saída desta camada será usada para calcular as probabilidades das classes.\n",
        "\n",
        "12. return F.log_softmax(x, dim=1)\n",
        "-> Esta linha aplica a função log_softmax à saída da última camada linear.\n",
        "-> F.log_softmax(x, dim=1) calcula o logaritmo da função softmax. O dim=1 especifica que o softmax deve ser calculado ao longo da dimensão das classes (a segunda dimensão, já que a primeira dimensão é o batch).\n",
        "-> O log_softmax é comumente usado em problemas de classificação com perda de entropia cruzada (Cross-Entropy Loss), pois é numericamente mais estável do que calcular o softmax separadamente e depois aplicar o logaritmo.\n",
        "Resumindo:\n",
        "\n",
        "  Este código define uma rede neural com três camadas lineares totalmente conectadas, com ativações ReLU entre as duas primeiras camadas lineares. A última camada aplica a função log_softmax para obter as probabilidades logarítmicas das classes. Esta arquitetura é comumente usada para tarefas de classificação, especialmente com o dataset MNIST.\n",
        "\n",
        "Em termos de fluxo de dados:\n",
        "\n",
        "-> A entrada x (uma imagem 28x28 achatada em um vetor de 784 elementos) passa pela primeira camada linear (self.linear1) e pela ativação ReLU.\n",
        "-> A saída desta etapa passa pela segunda camada linear (self.linear2) e por outra ativação ReLU.\n",
        "-> Finalmente, a saída passa pela terceira camada linear (self.linear3) e pela função log_softmax para produzir as probabilidades logarítmicas das 10 classes.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Rede neural da estrutura InceptionV3\n",
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo, self).__init__()\n",
        "    self.linear1 = nn.Linear(28*28, 128) # Camada de entrada, no qual utiliza 784 neurônios que se ligam a 128\n",
        "    self.linear2 = nn.Linear(128, 64) # Camada interna 1, no qual se utilia 128 neurônios que se ligam a 64\n",
        "    self.linear3 = nn.Linear(64, 10) # Camada interna 2, no qual se utiliza 10 neurônios que se ligam a 10\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.linear1(x)) # Função de ativação da camada de entrada para a camada interna 1\n",
        "    x = F.relu(self.linear2(x)) # Função de ativação da camada interna 1 para a camada interna 2\n",
        "    x = self.linear3(x) # Função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "    return F.log_softmax(x, dim=1) # Dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "lfizGwVNk-7R"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Explicação da função abaixo:\n",
        "\n",
        "1. def treino(modelo, trainloader, device):\n",
        "-> Esta linha define uma função chamada treino que recebe três argumentos:\n",
        "-> modelo: O modelo da rede neural a ser treinado.\n",
        "-> trainloader: O DataLoader que fornece os dados de treinamento em lotes (batches).\n",
        "-> device: O dispositivo a ser usado para treinamento (CPU ou GPU).\n",
        "\n",
        "2. otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
        "-> Esta linha define o otimizador. O otimizador é responsável por atualizar os pesos do modelo durante o treinamento.\n",
        "-> optim.SGD: Usa o Stochastic Gradient Descent (SGD) como otimizador. SGD é um algoritmo iterativo para otimizar uma função diferenciável.\n",
        "-> modelo.parameters(): Retorna um iterador sobre todos os parâmetros treináveis do modelo. O otimizador precisa saber quais parâmetros atualizar.\n",
        "-> lr=0.01: Define a taxa de aprendizado (learning rate) como 0.01. A taxa de aprendizado controla o tamanho do passo que o otimizador dá na direção do mínimo da função de perda.\n",
        "-> momentum=0.5: Define o momentum como 0.5. Momentum ajuda o otimizador a superar mínimos locais e acelera a convergência em direções relevantes.\n",
        "\n",
        "3. inicio = time()\n",
        "-> Esta linha inicia um timer para medir o tempo de treinamento.\n",
        "\n",
        "4. criterio = nn.NLLLoss()\n",
        "-> Define a função de perda (loss function) como Negative Log Likelihood Loss (nn.NLLLoss). Esta função de perda é comumente usada em problemas de classificação multiclasse quando a saída do modelo é um log-softmax (como no seu caso, com F.log_softmax).\n",
        "\n",
        "5. EPOCH = 10\n",
        "-> Define o número de épocas (epochs) como 10. Uma época é uma passagem completa por todo o conjunto de dados de treinamento.\n",
        "\n",
        "6. modelo.train()\n",
        "-> Esta linha coloca o modelo no modo de treinamento. Isso é importante porque algumas camadas, como Dropout e Batch Normalization, se comportam de maneira diferente durante o treinamento e a avaliação.\n",
        "\n",
        "7. for epoch in range(EPOCH):\n",
        "-> Inicia o loop principal de treinamento, iterando sobre as épocas.\n",
        "\n",
        "8. perda_acumulada = 0\n",
        "-> Inicializa uma variável para armazenar a perda acumulada durante cada época.\n",
        "\n",
        "9. for imagens, etiquetas in trainloader:\n",
        "-> Este é o loop interno que itera sobre os lotes (batches) de dados fornecidos pelo trainloader.\n",
        "-> imagens: Um lote de imagens de entrada.\n",
        "-> etiquetas: As etiquetas (labels) correspondentes às imagens.\n",
        "\n",
        "10. imagens = imagens.view(imagens.shape[0] , -1)\n",
        "-> Esta linha reformata as imagens.\n",
        "-> imagens.view(imagens.shape[0], -1): Achata cada imagem em um vetor. imagens.shape[0] mantém o tamanho do lote (batch size), e -1 calcula automaticamente o tamanho do vetor achatado (28*28 = 784 no caso de imagens 28x28). Isso é necessário porque as camadas lineares (nn.Linear) esperam entradas unidimensionais.\n",
        "\n",
        "11. otimizador.zero_grad()\n",
        "-> Zera os gradientes do otimizador. Isso é crucial porque os gradientes são acumulados a cada chamada de backward(). Você precisa zerá-los antes de calcular os gradientes para o próximo lote.\n",
        "\n",
        "12. output = modelo(imagens.to(device))\n",
        "-> Passa as imagens pelo modelo.\n",
        "-> imagens.to(device): Move as imagens para o dispositivo especificado (CPU ou GPU).\n",
        "-> modelo(imagens.to(device)): Executa o método forward do modelo, calculando a saída da rede para as imagens de entrada.\n",
        "\n",
        "13. perda_instantanea = criterio(output, etiquetas.to(device))\n",
        "-> Calcula a perda (loss) para o lote atual.\n",
        "-> etiquetas.to(device): Move as etiquetas para o mesmo dispositivo que as imagens.\n",
        "-> criterio(output, etiquetas.to(device)): Calcula a perda usando a função de perda definida anteriormente (nn.NLLLoss).\n",
        "\n",
        "14. perda_instantanea.backward()\n",
        "-> Executa a retropropagação (backpropagation). Este passo calcula os gradientes da perda em relação aos parâmetros do modelo.\n",
        "\n",
        "15. otimizador.step()\n",
        "-> Atualiza os pesos do modelo usando os gradientes calculados.\n",
        "\n",
        "16. perda_acumulada += perda_instantanea.item()\n",
        "-> Adiciona a perda do lote atual à perda acumulada da época. .item() extrai o valor numérico da perda (que é um tensor de um único elemento).\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def treino(modelo, trainloader, device):\n",
        "  # Otimizador do modelo\n",
        "  otimizador = optim.SGD(\n",
        "      modelo.parameters(),\n",
        "      lr=0.01,\n",
        "      momentum=0.5\n",
        "  )\n",
        "\n",
        "  inicio = time() # Timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "  criterio = nn.NLLLoss() # Definindo o critério para calcular a perda\n",
        "\n",
        "  EPOCH = 10 # Numero de epochs que o algoritmo rodará\n",
        "\n",
        "  modelo.train() # Ativando o modo de treinamento do modelo\n",
        "\n",
        "  # Looping para o treinamento das Epochs\n",
        "  for epoch in range(EPOCH):\n",
        "\n",
        "    perda_acumulada = 0 # Variável para calcular a perda acumulada\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "\n",
        "      imagens = imagens.view(imagens.shape[0] , -1) # Ajuste da imagem para vetores de 28*28\n",
        "      otimizador.zero_grad() # Zera os gradientes\n",
        "\n",
        "      output = modelo(imagens.to(device)) # Colocando os daados no modelo\n",
        "\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device)) # Calcula a perda da epoch em questão\n",
        "\n",
        "      perda_instantanea.backward() # Back Propagation a partir da perda\n",
        "\n",
        "      otimizador.step() # Atualiza os pesos e a bias\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item() # Adiciona a perda instantânea à perda acumulada\n",
        "\n",
        "    else:\n",
        "      print(\"Epoch {} - Perda Resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "  print(\"\\nTempo de treino (em minutos) = \", (time()-inicio)/60)"
      ],
      "metadata": {
        "id": "Xej5yCHLoxDW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Comparar uma imagem que não foi treinada com uma imagem que foi treinada, para validar se a Rede Neural aprendeu a imagem ou não\n",
        "\n",
        "def validacao(modelo, valloader, device):\n",
        "  conta_correta, conta_todas = 0, 0\n",
        "\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, 784)\n",
        "\n",
        "      # Desativar o autograd para acelerar a validação, Grafos computacionais tem um custo alto de processamento\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device)) # Output do modelo em escala logaritmica\n",
        "\n",
        "      ps = torch.exp(logps) # Converte o output do modelo em escala linear\n",
        "\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "\n",
        "      etiqueta_pred = probab.index(max(probab)) # Conveste o tensor em um numero, no caso, o numero que o modelo previu\n",
        "\n",
        "      etiqueta_certa = etiquetas.numpy()[i]\n",
        "\n",
        "      if(etiqueta_certa == etiqueta_pred): # Compara a previsão com o valor correto\n",
        "        conta_correta += 1\n",
        "\n",
        "      conta_todas += 1\n",
        "\n",
        "  print(\"Total de imagens testadas =\", conta_todas)\n",
        "  print(\"\\nPrecisão do modelo = {}%\".format(conta_correta*100/conta_todas))\n",
        "#"
      ],
      "metadata": {
        "id": "qywfLIBytEcq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Definindo o dispositivo, ele valida se a placa tem cuda, caso não usar o CPU (Apenas a NVidea possui suporte para o CUDA)\n",
        "\n",
        "modelo = Modelo().to(device)"
      ],
      "metadata": {
        "id": "2_8MhZMC65S4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino(modelo, trainloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fga0ivJK7u51",
        "outputId": "d6c04dc7-0751-4e4f-d0ab-72c05b6b38c7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Perda Resultante: 1.1671097186773316\n",
            "Epoch 2 - Perda Resultante: 0.37850742369318313\n",
            "Epoch 3 - Perda Resultante: 0.3140687381646145\n",
            "Epoch 4 - Perda Resultante: 0.27428134183671427\n",
            "Epoch 5 - Perda Resultante: 0.24337569487565108\n",
            "Epoch 6 - Perda Resultante: 0.21640971302986145\n",
            "Epoch 7 - Perda Resultante: 0.1944792133563363\n",
            "Epoch 8 - Perda Resultante: 0.17562134657650869\n",
            "Epoch 9 - Perda Resultante: 0.15937194523256598\n",
            "Epoch 10 - Perda Resultante: 0.1459749733099837\n",
            "\n",
            "Tempo de treino (em minutos) =  1.4327752510706584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validacao(modelo, valloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nnN_9-i9ZfA",
        "outputId": "e62dfaff-d296-4e7a-f941-fbc7bdaa3b62"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imagens testadas = 10000\n",
            "\n",
            "Precisão do modelo = 95.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sMsmp5HT9Rmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}